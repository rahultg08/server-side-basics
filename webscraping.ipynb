{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"29wwZVFJzv0-"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1676307530121,"user":{"displayName":"Rahul T G Information Science","userId":"08230065169986844077"},"user_tz":-330},"id":"ZIUuJJozr9MM","outputId":"c678ae14-5ce3-4130-ea7d-f76843067c6b"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' \\nWebscraping:\\nWebscraping is a process of extracting information from a website and can easily\\nbe accomplished within a matter of minutes\\n\\n '"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["''' \n","Webscraping:\n","Webscraping is a process of extracting information from a website and can easily\n","be accomplished within a matter of minutes\n","\n"," '''"]},{"cell_type":"markdown","metadata":{"id":"y_52qxW4wm-_"},"source":["Beautiful Soup:\n","\n","            Python\n","          /       \\\n","         /         \\\n","    Requests ---- Beautiful Soup\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yEsvBu56tv5r"},"outputs":[],"source":["from bs4 import BeautifulSoup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1676308695763,"user":{"displayName":"Rahul T G Information Science","userId":"08230065169986844077"},"user_tz":-330},"id":"VPKar-T6xdmh","outputId":"eb24c931-8d61-4ef6-be61-f6a2c63ce874"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n\\nWebpage HTML as a string in the variable HTML. To parse a document, pass it into\\nthe\\u202fBeautifulSoup\\u202fconstructor. We get the Beautiful Soup\\u202fobject , soup, which\\nrepresents the document as a nested data structure.\\n\\n'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","\n","Webpage HTML as a string in the variable HTML. To parse a document, pass it into\n","the BeautifulSoup constructor. We get the Beautiful Soup object , soup, which\n","represents the document as a nested data structure.\n","\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WnRiliv1yMUW"},"outputs":[],"source":["html = '/content/drive/MyDrive/Colab Notebooks/API/webpage.html'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1676309195830,"user":{"displayName":"Rahul T G Information Science","userId":"08230065169986844077"},"user_tz":-330},"id":"qK3B9JQc0FCA","outputId":"540eeebe-a550-4eff-ad8b-ab3a10d44ac0"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Colab Notebooks/API/webpage.html'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["html"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1676309237719,"user":{"displayName":"Rahul T G Information Science","userId":"08230065169986844077"},"user_tz":-330},"id":"A-x9AfnI0Gak","outputId":"cf976352-2040-4e85-8069-0bc3d8725fbc"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/bs4/__init__.py:270: UserWarning: \"b'/content/drive/MyDrive/Colab Notebooks/API/webpage.html'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n","  warnings.warn(\n"]}],"source":["soup = BeautifulSoup(html, 'html5lib')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3LD4Ge660Qy4"},"outputs":[],"source":["tag_object = soup.title"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1676309287439,"user":{"displayName":"Rahul T G Information Science","userId":"08230065169986844077"},"user_tz":-330},"id":"aUb7qfWh0W3s","outputId":"a578e9aa-5036-47bb-9588-ca3aa2c27d2a"},"outputs":[{"name":"stdout","output_type":"stream","text":["None\n"]}],"source":["print(tag_object)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L-gY8Inw0abT"},"outputs":[],"source":["# Necessary imports\n","import sys\n","import urllib.request\n","  \n","# Save a reference to the original\n","# standard output\n","original_stdout = sys.stdout\n","  \n","# as an example, taken my article list\n","# published link page and stored in local\n","with urllib.request.urlopen('https://auth.geeksforgeeks.org/user/priyarajtt/articles') as webPageResponse:\n","    outputHtml = webPageResponse.read()\n","  \n","# Scraped contents are placed in \n","# samplehtml.html file and getting\n","# used for next set of examples\n","with open('samplehtml.html', 'w') as f:\n","      \n","    # Here the  standard output is \n","    # written to the file that we \n","    # used above\n","    sys.stdout = f\n","    print(outputHtml)\n","      \n","    # Reset the standard output to its \n","    # original value\n","    sys.stdout = original_stdout"]},{"cell_type":"markdown","metadata":{"id":"AzdE5s44AGJH"},"source":["Webpage example"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ECzX6U1t1UMu"},"outputs":[],"source":["import requests\n","from bs4 import BeautifulS"]},{"cell_type":"code","source":["# exercise"],"metadata":{"id":"nTrr52P7C9Vo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mamba install bs4==4.10.0 -y\n","!pip install lxml==4.6.4\n","!mamba install html5lib==1.1 -y\n","# !pip install requests==2.26.0"],"metadata":{"id":"2TUzaZqdC_bN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from bs4 import BeautifulSoup # this module helps in web scrapping.\n","import requests  # this module helps us to download a web page"],"metadata":{"id":"TxBa_pquDAzH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%html\n","<!DOCTYPE html>\n","<html>\n","<head>\n","<title>Page Title</title>\n","</head>\n","<body>\n","<h3><b id='boldest'>Lebron James</b></h3>\n","<p> Salary: $ 92,000,000 </p>\n","<h3> Stephen Curry</h3>\n","<p> Salary: $85,000, 000 </p>\n","<h3> Kevin Durant </h3>\n","<p> Salary: $73,200, 000</p>\n","</body>\n","</html>"],"metadata":{"id":"BLGE2m_gDA5U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["html=\"<!DOCTYPE html><html><head><title>Page Title</title></head><body><h3><b id='boldest'>Lebron James</b></h3><p> Salary: $ 92,000,000 </p><h3> Stephen Curry</h3><p> Salary: $85,000, 000 </p><h3> Kevin Durant </h3><p> Salary: $73,200, 000</p></body></html>\""],"metadata":{"id":"hjQ94512DA9D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["soup = BeautifulSoup(html, \"html.parser\")"],"metadata":{"id":"B_eqRCLiDBA0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(soup.prettify())"],"metadata":{"id":"RQp7DrJMDKEo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tag_object=soup.title\n","print(\"tag object:\",tag_object)"],"metadata":{"id":"-ndF9j-TDLxf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"tag object type:\",type(tag_object))"],"metadata":{"id":"n-SwaCSZDNRU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tag_object=soup.h3\n","tag_object"],"metadata":{"id":"zgV9LBHfDN8x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Children, Parents, and Siblings"],"metadata":{"id":"gerhLqmbDT51"}},{"cell_type":"code","source":["tag_child =tag_object.b\n","tag_child"],"metadata":{"id":"wPpPXZ2NDPy7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["parent_tag=tag_child.parent\n","parent_tag"],"metadata":{"id":"O4pzTsOoDQXO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tag_object"],"metadata":{"id":"FGV-WA8FDQaD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tag_object.parent"],"metadata":{"id":"fCpNZ695DQc9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sibling_1=tag_object.next_sibling\n","sibling_1"],"metadata":{"id":"Of2aFIqGDZXN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sibling_2=sibling_1.next_sibling\n","sibling_2"],"metadata":{"id":"y7sxLrLiDZaB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tag_child['id']"],"metadata":{"id":"feeVt-XcDgXO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tag_child.attrs"],"metadata":{"id":"8AWIPSkgDZcv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tag_child.get('id')"],"metadata":{"id":"s2FJLaMVDZe2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Navigable String"],"metadata":{"id":"KiHzRA9DDjzO"}},{"cell_type":"code","source":["tag_string=tag_child.string\n","tag_string"],"metadata":{"id":"5ErjIuSqDkJ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(tag_string)"],"metadata":{"id":"-qqH6w8XDn00"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["unicode_string = str(tag_string)\n","unicode_string"],"metadata":{"id":"6CjwbKT2DoFY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Filter"],"metadata":{"id":"nU5sTqh_DwyO"}},{"cell_type":"code","source":["%%html\n","<table>\n","  <tr>\n","    <td id='flight' >Flight No</td>\n","    <td>Launch site</td> \n","    <td>Payload mass</td>\n","   </tr>\n","  <tr> \n","    <td>1</td>\n","    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a></td>\n","    <td>300 kg</td>\n","  </tr>\n","  <tr>\n","    <td>2</td>\n","    <td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td>\n","    <td>94 kg</td>\n","  </tr>\n","  <tr>\n","    <td>3</td>\n","    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a> </td>\n","    <td>80 kg</td>\n","  </tr>\n","</table>"],"metadata":{"id":"MWRkYVJyDoIc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["table=\"<table><tr><td id='flight'>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr> <td>1</td><td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a></td><td>300 kg</td></tr><tr><td>2</td><td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a> </td><td>80 kg</td></tr></table>\""],"metadata":{"id":"pXDPNSaFDzQA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["table_bs = BeautifulSoup(table, \"html.parser\")"],"metadata":{"id":"AS1J61e0DzTH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["find All: find_all(name, attrs, recursive, string, limit, **kwargs)"],"metadata":{"id":"hWrWDtLwD5il"}},{"cell_type":"code","source":["table_rows=table_bs.find_all('tr')\n","table_rows"],"metadata":{"id":"AWU8DhTxDzVn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["first_row =table_rows[0]\n","first_row"],"metadata":{"id":"0uuW9_FVDzYU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(type(first_row))"],"metadata":{"id":"_DpINYQkEBBt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["first_row.td"],"metadata":{"id":"eTODr3uqEBEd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i,row in enumerate(table_rows):\n","    print(\"row\",i,\"is\",row)\n","    "],"metadata":{"id":"8C9GAyByEBJa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i,row in enumerate(table_rows):\n","    print(\"row\",i)\n","    cells=row.find_all('td')\n","    for j,cell in enumerate(cells):\n","        print('colunm',j,\"cell\",cell)"],"metadata":{"id":"_tq2T6WjEBNe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list_input=table_bs .find_all(name=[\"tr\", \"td\"])\n","list_input"],"metadata":{"id":"3zDHgZv4EBQU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Attributes"],"metadata":{"id":"Rdy3-ZzTEK-9"}},{"cell_type":"code","source":["table_bs.find_all(id=\"flight\")"],"metadata":{"id":"O59UY694ELhf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list_input=table_bs.find_all(href=\"https://en.wikipedia.org/wiki/Florida\")\n","list_input"],"metadata":{"id":"ecG-z8aUELy8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["table_bs.find_all(href=True)"],"metadata":{"id":"AgrKbrPREP6R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Downloading And Scraping The Contents Of A Web Page"],"metadata":{"id":"rLSUTtlQEZbI"}},{"cell_type":"code","source":["url = \"http://www.ibm.com\""],"metadata":{"id":"rwkhFMamEZ9v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data  = requests.get(url).text "],"metadata":{"id":"khPby7w5EbW7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["soup = BeautifulSoup(data,\"html.parser\")  # create a soup object using the variable 'data'"],"metadata":{"id":"qw8MGgkYEclZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for link in soup.find_all('a',href=True):  # in html anchor/link is represented by the tag <a>\n","\n","    print(link.get('href'))\n"],"metadata":{"id":"wQRGWULoEecq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Scrape data from HTML tables"],"metadata":{"id":"tssvpzM5Eixh"}},{"cell_type":"code","source":["#The below url contains an html table with data about colors and color codes.\n","url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html\""],"metadata":{"id":"JP1HKwRDEfFA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get the contents of the webpage in text format and store in a variable called data\n","data  = requests.get(url).text"],"metadata":{"id":"_Ysm8tD4EfHl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["soup = BeautifulSoup(data,\"html.parser\")"],"metadata":{"id":"rFSoog9hEfKr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#find a html table in the web page\n","table = soup.find('table') # in html table is represented by the tag <table>"],"metadata":{"id":"EbdHpFpFEfNH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get all rows from the table\n","for row in table.find_all('tr'): # in html table row is represented by the tag <tr>\n","    # Get all columns in each row.\n","    cols = row.find_all('td') # in html a column is represented by the tag <td>\n","    color_name = cols[2].string # store the value in column 3 as color_name\n","    color_code = cols[3].string # store the value in column 4 as color_code\n","    print(\"{}--->{}\".format(color_name,color_code))"],"metadata":{"id":"Y3dnh4yWEtVx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pSnxYBaPEtZD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DcYwalJzEtbd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gYqyKPX5Etd8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zzc32DPKEtgQ"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMLMhgxsUf1badM4OjmjK+u"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}